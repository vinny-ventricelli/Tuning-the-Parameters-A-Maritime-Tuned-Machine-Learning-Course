{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# K-Means Clustering with Ship Data\n",
        "**Before you begin.**\n",
        "You will edit this Colab notebook by adding/changing code and adding text to answer questions and provide explanations and insights.  When you are finished, you can print to PDF in order to easily generate a report.  To earn full points,  \n",
        "*   try your best to avoid code that extends past the vertical bar in code cells.  It will not print well.\n",
        "*   print text along with the answer/explanation, if answering/explaining with code.  For example, use `print(f'The bias is {bias}.')` instead of `print(bias)`.  This way, your instructor knows that you know how to interpret what you are seeing,\n",
        "*   use italicized text if answering/explaining with text.  This will help your answers stand out, and\n",
        "*   identify and explain some key observations that were not explcitily asked for in this assignment.  Sometimes the instructor wants to see if you know what to look for on your own.\n",
        "\n",
        "You can add cells of either text or code by hovering over the horizontal edge of the cell just before where you want to add a new cell.  Click either \"+ text\" or \"+ code\", as appopriate.  You may have to click in the previous cell in order to see \"+ text\" or \"+ code\"\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "eU1907D9_K_M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Assignment summary.** K-means clustering is an unsupervised algorithm that can identify natural groupings within a dataset.  One application is pixel quantization in image processing, in which an image of many different color hues is approximated with fewer colors in order to reduce file size. This assignment will have you investigate the ability of the K-means clustering algorithm to quantize the pixel values in a single image in the [San Francisco ship aerial imagery dataset](https://www.kaggle.com/datasets/rhammell/ships-in-satellite-imagery).  As opposed to using the black-box function, you will code the K-means clustering algorithm from scratch and observe how the choice of K affects the image quantization. \n",
        "\n",
        "The ship dataset is the same in this assignment as in the previous assignments, except we will work with color images instead of black and white.  \n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "MuQ00fLRdS9c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Import the data.** Connect this Colab notebook to your Google Drive.  This code is complete."
      ],
      "metadata": {
        "id": "JC__gq5-KuUW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m85_Q6yS1jSu"
      },
      "outputs": [],
      "source": [
        "# Given your permission, this will connect your notebook to your Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load in the ship data from Google Drive and display one selected image.  The name of the folder containing all the ships should be `shipdata_MLcourse`, and the dataset should be named `img_data_color.pickle`; otherwise you need to change the code below accordingly.  The variable `img_data_color` contains all of the pixel information for each of the images.  Colored images contain three channels: red (R), green (G), and blue (B).  The pixel hue we perceive is a combination of these three channels, expressed as a three-dimensional vector.  Thus, the dataset is a numpy array with four axes:\n",
        "\n",
        "\n",
        "*   Axis 0 is the image axis.  Index it to retrieve different images.\n",
        "*   Axis 1 and 2 are the length, width.  Index them to retrieve different pixels values.\n",
        "\n",
        "*   Axis 3 is the channel axis.  Index it to retrieve the amount or R, G, or B.\n",
        "\n",
        "This code below is complete."
      ],
      "metadata": {
        "id": "txtrYQHFGNVW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Now the ship data can be loaded into the notebook (presuming you uploaded..\n",
        "# ...the data previously into your Google Drive)\n",
        "import os, pickle\n",
        "my_path = '/content/drive/My Drive/shipdata_MLcourse'\n",
        "with open(os.path.join(my_path, 'img_data_color.pickle'), 'rb') as handle:\n",
        "  img_data_color = pickle.load(handle)\n",
        "print(f'The shape of img_data is {img_data_color.shape}.')          "
      ],
      "metadata": {
        "id": "9JFyQCLT271k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7dc2d684-52b9-4521-f093-b54aa3d6d86f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The shape of img_data is (3905, 80, 80, 3).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check out some of the ship images! Change the value of `my_index` to view different images.  Remember that Python indexing starts at zero.  The code is complete.  With `my_index`, choose an image that looks relatively simple, like with `my_index = 6`.  This will serve as our test image moving foward.  (The algorithm will operate only on this image.)"
      ],
      "metadata": {
        "id": "9miOsOcfHUfx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "my_index = 6        # change this number\n",
        "img = img_data_color[my_index]\n",
        "cv2_imshow(img)  # display image"
      ],
      "metadata": {
        "id": "WT3fjwJBDJU3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In our application of pixel quantization, each pixel in our test image is a feature.  (Unlike previous assignments when each image was a feature.)  We can reorganize the selected image's 6400 pixels to place them in a 6400-by-3 array, optimal for K-means clustering.  The columns are R, G, B.  The code below is complete."
      ],
      "metadata": {
        "id": "u_nPgisbjWiK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "X = np.reshape(img, (6400,3))\n",
        "print(X.shape)"
      ],
      "metadata": {
        "id": "k5IQEpCCAiTr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Next, we will apply the K-means clustering algorithm to the test image.**  The number of means, `K`, in this case represents the number of hues and is usually a power of 2 (though it doesn't have to be). We will begin with `K = 16` hues.  Finish the code to cluster the pixels in three-dimensional space and determine the cluster centeroids (the means).  A summary of the algorithm is as follows:\n",
        "\n",
        "1.   Initialize the algorithm by choosing `K`and randomly selecting `K` unique pixels to serve as the initial means.\n",
        "2.   For each pixel, do the following: (1) Calculate `distances`,  the distance away each mean is from the *ii*th pixel, and (2) set the *ii*th cluster index in `cluster` to the *jj*th mean that is closest.\n",
        "3.   Using the cluster index, recalulate the means `means` of each cluster\n",
        "4.   Repeat Steps 2 and 3 many times, say 100.\n",
        "\n",
        "Note that `K` may not be larger than 32, the number of hues in the original image.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Bn1gcac2YzVJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ----initialization (Step 1)-----\n",
        "K = 2**1                           # 16 hues\n",
        "np.random.seed(42)                 # seed the RNG\n",
        "idx = np.random.permutation(len(X))\n",
        "means = X[idx[:K]]                 # the K means are randomly chosen data points\n",
        "clusters = np.zeros(len(X))        # clustering index to be filled\n",
        "# ---------end Step 1 ------------\n",
        "\n",
        "for iteration in range(100):\n",
        "  \n",
        "  # ----cluster assignment (Step 2)---------------\n",
        "  # TODO: Complete Step 2\n",
        "  for ii,pixel in enumerate(X):\n",
        "    distances =                # use np.linalg.norm\n",
        "    index_min =                # use np.argmin\n",
        "    clusters[ii] =             # set the iith item in clusters to index_min\n",
        "  # --------------end Step 2----------------------\n",
        "  \n",
        "  # ---------update means (Step 3) ---------------\n",
        "  for jj,m in enumerate(means):\n",
        "    # TODO: Complete Step 3\n",
        "    means[jj] =   # use np.where\n",
        "  # ----------------end Step 3--------------------  \n",
        "\n"
      ],
      "metadata": {
        "id": "xAMpIXTIW-uQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "With the correct means and clusters variables, we can view the quantized result.  The below code is finished."
      ],
      "metadata": {
        "id": "k8FV4cwPwH1F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_image = np.zeros(X.shape)   # the new image will have the same shape as X\n",
        "for ii,pixel in enumerate(X):   # pixel values and indices must be integers\n",
        "  new_image[ii] = means[int(clusters[ii])].astype(int) # assign the correct mean\n",
        "cv2_imshow(new_image.reshape(img.shape)) # display image "
      ],
      "metadata": {
        "id": "UUVhVAiHwgNP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can measure the quantization error between `new_image` and `X` by averaging the difference in RGB pixel vectors over all the image pixels.  Use `np.linalg.norm` and `np.mean` to do so."
      ],
      "metadata": {
        "id": "ViIonu8yxYMr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: calculate and display the quantization error\n"
      ],
      "metadata": {
        "id": "dshNv7Epx63N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Go back and change the hyperparameters.** Change the value of K to 8, 4, and 2.  Each time, notice the image the the quantization error.  What do you observe?"
      ],
      "metadata": {
        "id": "LNaK6C_P21ho"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Visualize the clustering.** Let's ignore the blue (B) channel, the last channel, so that the pixel vectors become two-dimensional, and we can observe their locations in a two-dimensional scatter plot.  We will initially make four clusters, so go back and rerun the previous few blocks with `K = 4`, if you need to.  The four clusters will appear as separate colors, unrelated to RGB channels.  Here, the colors are simply a visual representation of clustering.  The code will also plot the cluster center as a black circle.  Describe what you see and why.  The code below is complete.\n",
        "\n",
        "Then, rerun your code for` K = 2 `and observe the clustering.  Describe what you see and why."
      ],
      "metadata": {
        "id": "G6LqKz0p35wV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "for ii in range(K):\n",
        "  plt.scatter(X[np.where(clusters==ii),0],X[np.where(clusters==ii),1]) \n",
        "  plt.scatter(means[ii,0],means[ii,1], c=\"black\")\n",
        "plt.xlabel('red value')\n",
        "plt.ylabel('green value')  "
      ],
      "metadata": {
        "id": "hHbSFERW4oXF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Go further.** Upload your own picture---one rich in colors---to Google Drive, and import it into Colab.  To keep processing time relatively short, choose an image that is small or one that you can crop.  Experiment with values of `K`---try 256, 512, 4, 2, etc.---and observe the results.  What do you notice?  Even with a small image, by today's standards, you can expect processing to take possibly several minutes."
      ],
      "metadata": {
        "id": "hwfHFvRS7ZuX"
      }
    }
  ]
}